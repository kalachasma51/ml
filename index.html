1.12/30/22, 1:10 PM Chronic Kidney Disease.ipynb - Colaboratory
https://colab.research.google.com/drive/15vbtNFSEkdcYIBkrQ5c4YympdVD5cCpk#scrollTo=FMMPqKRlon01&printMode=true 1/8
1
2
3
4
5
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
sns.set_theme(color_codes = True)
https://www.kaggle.com/datasets/abhia1999/chronic-kidney-disease
Dataset :
Bp Sg Al Su Rbc Bu Sc Sod Pot Hemo Wbcc Rbcc Htn Class
0 80.0 1.020 1.0 0.0 1.0 36.0 1.2 137.53 4.63 15.4 7800.0 5.20 1.0 1
1 50.0 1.020 4.0 0.0 1.0 18.0 0.8 137.53 4.63 11.3 6000.0 4.71 0.0 1
2 80.0 1.010 2.0 3.0 1.0 53.0 1.8 137.53 4.63 9.6 7500.0 4.71 0.0 1
3 70.0 1.005 4.0 0.0 1.0 56.0 3.8 111.00 2.50 11.2 6700.0 3.90 1.0 1
4 80.0 1.010 2.0 0.0 1.0 26.0 1.4 137.53 4.63 11.6 7300.0 4.60 0.0 1
... ... ... ... ... ... ... ... ... ... ... ... ... ... ...
395 80.0 1.020 0.0 0.0 1.0 49.0 0.5 150.00 4.90 15.7 6700.0 4.90 0.0 0
396 70.0 1.025 0.0 0.0 1.0 31.0 1.2 141.00 3.50 16.5 7800.0 6.20 0.0 0
397 80.0 1.020 0.0 0.0 1.0 26.0 0.6 137.00 4.40 15.8 6600.0 5.40 0.0 0
398 60.0 1.025 0.0 0.0 1.0 50.0 1.0 135.00 4.90 14.2 7200.0 5.90 0.0 0
399 80.0 1.025 0.0 0.0 1.0 18.0 1.1 141.00 3.50 15.8 6800.0 6.10 0.0 0
400 rows Ã— 14 columns
1
2
df = pd.read_csv('new_model.csv')
df
Exploratory Data Analysis
<matplotlib.axes._subplots.AxesSubplot at 0x7f5187149ca0>
1 sns.countplot(data=df, x="Htn", hue="Class")
<matplotlib.axes._subplots.AxesSubplot at 0x7f5187146ee0>
1 sns.countplot(data=df, x="Rbc", hue="Class")
<matplotlib.axes._subplots.AxesSubplot at 0x7f518709ed90>
1 sns.histplot(data=df, x="Bp", hue="Class", multiple="stack")
12/30/22, 1:10 PM Chronic Kidney Disease.ipynb - Colaboratory
https://colab.research.google.com/drive/15vbtNFSEkdcYIBkrQ5c4YympdVD5cCpk#scrollTo=FMMPqKRlon01&printMode=true 2/8
Data Preprocessing
1 df.isnull().sum()
Bp 0
Sg 0
Al 0
Su 0
Rbc 0
Bu 0
Sc 0
Sod 0
Pot 0
Hemo 0
Wbcc 0
Rbcc 0
Htn 0
Class 0
dtype: int64
1
2
3
4
5
6
#replace 0 value with NaN
df_copy = df.copy(deep = True) #deep = True -> Buat salinan indeks dan data dalam dataframe
df_copy[['Bp','Sg','Bu','Sc','Sod','Pot','Hemo','Wbcc','Rbcc']] = df_copy[['Bp','Sg','Bu','Sc','Sod','Pot','Hemo','Wbcc','Rbcc']].replace(
# Showing the Count of NANs
print(df_copy.isnull().sum())
Bp 0
Sg 0
Al 0
Su 0
Rbc 0
Bu 0
Sc 0
Sod 0
Pot 0
Hemo 0
Wbcc 0
Rbcc 0
Htn 0
Class 0
dtype: int64
Check if the class label is balanced or not
1 250
0 150
Name: Class, dtype: int64
/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From
warnings.warn(
1
2
sns.countplot(df['Class'])
print(df.Class.value_counts())
Do Oversampling Minority Class to Balance the class label
1
2
3
4
5
6
7
8
9
10
11
from sklearn.utils import resample
#create two different dataframe of majority and minority class
df_majority = df[(df['Class']==1)]
df_minority = df[(df['Class']==0)]
# upsample minority class
df_minority_upsampled = resample(df_minority,
n_samples= 250,
random_state=0)
# Combine majority class with upsampled minority class
df2 = pd.concat([df_minority_upsampled, df_majority])
1
2
sns.countplot(df2['Class'])
print(df2.Class.value_counts())
12/30/22, 1:10 PM Chronic Kidney Disease.ipynb - Colaboratory
https://colab.research.google.com/drive/15vbtNFSEkdcYIBkrQ5c4YympdVD5cCpk#scrollTo=FMMPqKRlon01&printMode=true 3/8
/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From
warnings.warn(
0 250
1 250
Name: Class, dtype: int64
Check the Outlier using Boxplot
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186ed9970>
1 sns.boxplot(x=df2["Bp"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186e83d90>
1 sns.boxplot(x=df2["Sg"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186de2be0>
1 sns.boxplot(x=df2["Bu"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186dc1dc0>
1 sns.boxplot(x=df2["Sc"])
1 sns.boxplot(x=df2["Sod"])
12/30/22, 1:10 PM Chronic Kidney Disease.ipynb - Colaboratory
https://colab.research.google.com/drive/15vbtNFSEkdcYIBkrQ5c4YympdVD5cCpk#scrollTo=FMMPqKRlon01&printMode=true 4/8
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186d0c790>
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186e8aa60>
1 sns.boxplot(x=df2["Pot"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186cc4220>
1 sns.boxplot(x=df2["Hemo"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186c775b0>
1 sns.boxplot(x=df2["Wbcc"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186be32b0>
1 sns.boxplot(x=df2["Rbcc"])
Remove Outlier using Z-Score
1
2
3
4
import scipy.stats as stats
z = np.abs(stats.zscore(df2))
data_clean = df2[(z<3).all(axis = 1)]
data_clean.shape
(420, 14)
12/30/22, 1:10 PM Chronic Kidney Disease.ipynb - Colaboratory
https://colab.research.google.com/drive/15vbtNFSEkdcYIBkrQ5c4YympdVD5cCpk#scrollTo=FMMPqKRlon01&printMode=true 5/8
Heatmap Data Correlation
<matplotlib.axes._subplots.AxesSubplot at 0x7f5186b513a0>
1 sns.heatmap(data_clean.corr(), fmt='.2g')
1
2
#Rbc attribute is irrlevant, so we have to remove it
data_clean2 = df.drop(columns=['Rbc'])
1
2
3
4
corr = data_clean2[data_clean2.columns[1:]].corr()['Class'][:-1]
plt.plot(corr)
plt.xticks(rotation=90)
plt.show()
Machine Learning Model Building
1
2
X = data_clean2.drop('Class', axis=1)
y = data_clean2['Class']
1
2
3
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)
Random Forest
1
2
3
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(random_state=0)
rfc.fit(X_train, y_train)
RandomForestClassifier(random_state=0)
1
2
y_pred = rfc.predict(X_test)
print("Accuracy Score :", round(accuracy_score(y_test, y_pred)*100 ,2), "%")
Accuracy Score : 100.0 %
1
2
3
4
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
print('F-1 Score : ',(f1_score(y_test, y_pred)))
print('Precision Score : ',(precision_score(y_test, y_pred)))
print('Recall Score : ',(recall_score(y_test, y_pred)))
F-1 Score : 1.0
Precision Score : 1.0
Recall Score : 1.0
1
2
3
4
5
6
7
8
from sklearn.metrics import classification_report, confusion_matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,5))
sns.heatmap(data=cm,linewidths=.5, annot=True,square = True, cmap = 'Blues')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(rfc.score(X_test, y_test)*100)
plt.title(all_sample_title, size = 15)
12/30/22, 1:10 PM Chronic Kidney Disease.ipynb - Colaboratory
https://colab.research.google.com/drive/15vbtNFSEkdcYIBkrQ5c4YympdVD5cCpk#scrollTo=FMMPqKRlon01&printMode=true 6/8
Text(0.5, 1.0, 'Accuracy Score: 100.0')
KNearest Neighbor
1
2
3
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
KNeighborsClassifier()
1
2
y_pred = knn.predict(X_test)
print("Accuracy Score :", round(accuracy_score(y_test, y_pred)*100 ,2), "%")
Accuracy Score : 62.5 %
1
2
3
4
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
print('F-1 Score : ',(f1_score(y_test, y_pred)))
print('Precision Score : ',(precision_score(y_test, y_pred)))
print('Recall Score : ',(recall_score(y_test, y_pred)))
F-1 Score : 0.6875
Precision Score : 0.75
Recall Score : 0.6346153846153846
Text(0.5, 1.0, 'Accuracy Score: 62.5')
1
2
3
4
5
6
7
8
from sklearn.metrics import classification_report, confusion_matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,5))
sns.heatmap(data=cm,linewidths=.5, annot=True,square = True, cmap = 'Blues')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(knn.score(X_test, y_test)*100)
plt.title(all_sample_title, size = 15)
AdaBoost
1
2
3
from sklearn.ensemble import AdaBoostClassifier
ada = AdaBoostClassifier(random_state=0)
ada.fit(X_train, y_train)
AdaBoostClassifier(random_state=0)
1
2
y_pred = ada.predict(X_test)
print("Accuracy Score :", round(accuracy_score(y_test, y_pred)*100 ,2), "%")
Accuracy Score : 98.75 %
1
2
3
4
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
print('F-1 Score : ',(f1_score(y_test, y_pred)))
print('Precision Score : ',(precision_score(y_test, y_pred)))
print('Recall Score : ',(recall_score(y_test, y_pred)))
F-1 Score : 0.9902912621359222
Precision Score : 1.0
Recall Score : 0.9807692307692307
1
2
3
4
5
6
from sklearn.metrics import classification_report, confusion_matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,5))
sns.heatmap(data=cm,linewidths=.5, annot=True,square = True, cmap = 'Blues')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
12/30/22, 1:10 PM Chronic Kidney Disease.ipynb - Colaboratory
https://colab.research.google.com/drive/15vbtNFSEkdcYIBkrQ5c4YympdVD5cCpk#scrollTo=FMMPqKRlon01&printMode=true 7/8
Text(0.5, 1.0, 'Accuracy Score: 98.75')
7
8
all_sample_title = 'Accuracy Score: {0}'.format(ada.score(X_test, y_test)*100)
plt.title(all_sample_title, size = 15)
Logistic Regression
1
2
3
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(random_state = 0)
lr.fit(X_train, y_train)
/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
n_iter_i = _check_optimize_result(
LogisticRegression(random_state=0)
1
2
y_pred = lr.predict(X_test)
print("Accuracy Score :", round(accuracy_score(y_test, y_pred)*100 ,2), "%")
Accuracy Score : 93.75 %
1
2
3
4
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
print('F-1 Score : ',(f1_score(y_test, y_pred)))
print('Precision Score : ',(precision_score(y_test, y_pred)))
print('Recall Score : ',(recall_score(y_test, y_pred)))
F-1 Score : 0.9504950495049506
Precision Score : 0.9795918367346939
Recall Score : 0.9230769230769231
Text(0.5, 1.0, 'Accuracy Score: 93.75')
1
2
3
4
5
6
7
8
from sklearn.metrics import classification_report, confusion_matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,5))
sns.heatmap(data=cm,linewidths=.5, annot=True,square = True, cmap = 'Blues')
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
all_sample_title = 'Accuracy Score: {0}'.format(lr.score(X_test, y_test)*100)
plt.title(all_sample_title, size = 15)
12/30/22, 1:10 PM Chronic Kidney Disease.ipynb - Colaboratory
https://colab.research.google.com/drive/15vbtNFSEkdcYIBkrQ5c4YympdVD5cCpk#scrollTo=FMMPqKRlon01&printMode=true 8/8
î—Š 0s completed at 1:05 PM


-----------------------------------------------------------------------------------------------------------------------------------

  2.
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
sns.set_theme(color_codes=True)
df = pd.read_csv('heart.csv')
df
age sex cp trestbps chol fbs restecg thalach exang
oldpeak \
0 52 1 0 125 212 0 1 168 0
1.0
1 53 1 0 140 203 1 0 155 1
3.1
2 70 1 0 145 174 0 1 125 1
2.6
3 61 1 0 148 203 0 1 161 0
0.0
4 62 0 0 138 294 1 1 106 0
1.9
... ... ... .. ... ... ... ... ... ...
...
1020 59 1 1 140 221 0 1 164 1
0.0
1021 60 1 0 125 258 0 0 141 1
2.8
1022 47 1 0 110 275 0 0 118 1
1.0
1023 50 0 0 110 254 0 0 159 0
0.0
1024 54 1 0 120 188 0 1 113 0
1.4
slope ca thal target
0 2 2 3 0
1 0 0 3 0
2 0 0 3 0
3 2 1 3 0
4 1 3 2 0
... ... .. ... ...
1020 2 0 2 1
1021 1 1 3 0
1022 1 1 2 0
1023 2 0 2 1
1024 1 1 3 0
[1025 rows x 14 columns]
#Exploratory Data Analysis
sns.countplot(data=df, x="sex", hue="target")
<matplotlib.axes._subplots.AxesSubplot at 0x7f12320b2dc0>
sns.histplot(data=df, x="age", hue="target", multiple="stack")
<matplotlib.axes._subplots.AxesSubplot at 0x7f1232018f70>
sns.histplot(data=df, x="chol", hue="target", multiple="stack")
<matplotlib.axes._subplots.AxesSubplot at 0x7f1231b8b2e0>
sns.histplot(data=df, x="trestbps", hue="target", multiple="stack")
<matplotlib.axes._subplots.AxesSubplot at 0x7f1231b5c790>
sns.histplot(data=df, x="thalach", hue="target", multiple="stack")
<matplotlib.axes._subplots.AxesSubplot at 0x7f12318c8be0>
#Data Preprocessing
df.isnull().sum()
age 0
sex 0
cp 0
trestbps 0
chol 0
fbs 0
restecg 0
thalach 0
exang 0
oldpeak 0
slope 0
ca 0
thal 0
target 0
dtype: int64
sns.countplot(df['target'])
print(df.target.value_counts())
/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36:
FutureWarning: Pass the following variable as a keyword arg: x. From
version 0.12, the only valid positional argument will be `data`, and
passing other arguments without an explicit keyword will result in an
error or misinterpretation.
warnings.warn(
1 526
0 499
Name: target, dtype: int64
#Outlier Detection Using Boxplot
sns.boxplot(x=df["age"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f123176c7c0>
sns.boxplot(x=df["trestbps"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f1231746310>
sns.boxplot(x=df["chol"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f12316a3370>
sns.boxplot(x=df["thalach"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f1231670e20>
sns.boxplot(x=df["oldpeak"])
<matplotlib.axes._subplots.AxesSubplot at 0x7f1231646fa0>
#Outlier Removal Using Z-Score
import scipy.stats as stats
z = np.abs(stats.zscore(df))
data_clean = df[(z<3).all(axis = 1)]
data_clean.shape
(969, 14)
#Data Correlation using Heatmap
sns.heatmap(data_clean.corr(), fmt='.2g')
<matplotlib.axes._subplots.AxesSubplot at 0x7f12315aea00>
#Correlation between Class and other attributes
corr = data_clean[data_clean.columns[1:]].corr()['target'][:-1]
plt.plot(corr)
plt.xticks(rotation=90)
plt.show()
#Machine Learning Model Building
X = data_clean.drop('target', axis=1)
y = data_clean['target']
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
X_train, X_test, y_train, y_test = train_test_split(X,y,
test_size=0.2,random_state=0)
#Decision Tree
from sklearn.tree import DecisionTreeClassifier
dtree = DecisionTreeClassifier(random_state = 0)
dtree.fit(X_train, y_train)
DecisionTreeClassifier(random_state=0)
y_pred = dtree.predict(X_test)
print("Accuracy Score :", round(accuracy_score(y_test,
y_pred)*100 ,2), "%")
Accuracy Score : 100.0 %
from sklearn.metrics import accuracy_score, f1_score, precision_score,
recall_score
print('F-1 Score : ',(f1_score(y_test, y_pred)))
print('Precision Score : ',(precision_score(y_test, y_pred)))
print('Recall Score : ',(recall_score(y_test, y_pred)))
F-1 Score : 1.0
Precision Score : 1.0
Recall Score : 1.0
#Feature Importance
imp_df = pd.DataFrame({
"Feature Name": X_train.columns,
"Importance": dtree.feature_importances_
})
fi = imp_df.sort_values(by="Importance", ascending=False)
plt.figure(figsize=(10,8))
sns.barplot(data=fi, x='Importance', y='Feature Name')
plt.title('Feature Importance Each Attributes', fontsize=18)
plt.xlabel ('Importance', fontsize=16)
plt.ylabel ('Feature Name', fontsize=16)
plt.show()
#Random Forest
from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(random_state=0)
rfc.fit(X_train, y_train)
RandomForestClassifier(random_state=0)
y_pred = rfc.predict(X_test)
print("Accuracy Score :", round(accuracy_score(y_test,
y_pred)*100 ,2), "%")
Accuracy Score : 100.0 %
from sklearn.metrics import accuracy_score, f1_score, precision_score,
recall_score
print('F-1 Score : ',(f1_score(y_test, y_pred)))
print('Precision Score : ',(precision_score(y_test, y_pred)))
print('Recall Score : ',(recall_score(y_test, y_pred)))
F-1 Score : 1.0
Precision Score : 1.0
Recall Score : 1.0
#Feature Importance
imp_df = pd.DataFrame({
"Feature Name": X_train.columns,
"Importance": rfc.feature_importances_
})
fi = imp_df.sort_values(by="Importance", ascending=False)
plt.figure(figsize=(10,8))
sns.barplot(data=fi, x='Importance', y='Feature Name')
plt.title('Feature Importance Each Attributes', fontsize=18)
plt.xlabel ('Importance', fontsize=16)
plt.ylabel ('Feature Name', fontsize=16)
plt.show()
#AdaBoost
from sklearn.ensemble import AdaBoostClassifier
ada = AdaBoostClassifier(random_state=0)
ada.fit(X_train, y_train)
AdaBoostClassifier(random_state=0)
y_pred = ada.predict(X_test)
print("Accuracy Score :", round(accuracy_score(y_test,
y_pred)*100 ,2), "%")
Accuracy Score : 93.3 %
from sklearn.metrics import accuracy_score, f1_score, precision_score,
recall_score
print('F-1 Score : ',(f1_score(y_test, y_pred)))
print('Precision Score : ',(precision_score(y_test, y_pred)))
print('Recall Score : ',(recall_score(y_test, y_pred)))
F-1 Score : 0.9365853658536586
Precision Score : 0.9411764705882353
Recall Score : 0.9320388349514563
#Feature Importance
imp_df = pd.DataFrame({
"Feature Name": X_train.columns,
"Importance": ada.feature_importances_
})
fi = imp_df.sort_values(by="Importance", ascending=False)
plt.figure(figsize=(10,8))
sns.barplot(data=fi, x='Importance', y='Feature Name')
plt.title('Feature Importance Each Attributes', fontsize=18)
plt.xlabel ('Importance', fontsize=16)
plt.ylabel ('Feature Name', fontsize=16)
plt.show()


---------------------------------------------------------------------------------------------------------------
3.
  12/28/22, 2:20 PM Flight Price Prediction.ipynb - Colaboratory
https://colab.research.google.com/drive/1So4Cg5JF6SMfEj-k8bmOkkWxozuf7eXk#scrollTo=0NgCPHWvmApW&printMode=true 1/5
1
2
3
4
5
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
sns.set_theme(color_codes = True)
Unnamed:
0 airline flight source_city departure_time stops arrival_tim
0 0 SpiceJet SG-
8709 Delhi Evening zero Nigh
1 1 SpiceJet SG-
8157 Delhi Early_Morning zero Mornin
2 2 AirAsia I5-764 Delhi Early_Morning zero Early_Mornin
3 3 Vistara UK-
995 Delhi Morning zero Afternoo
4 4 Vistara UK-
963 Delhi Morning zero Mornin
... ... ... ... ... ... ... .
300148 300148 Vistara UK-
822 Chennai Morning one Evenin
300149 300149 Vistara UK-
826 Chennai Afternoon one Nigh
300150 300150 Vistara UK-
832 Chennai Early_Morning one Nigh
300151 300151 Vistara UK-
828 Chennai Early_Morning one Evenin
300152 300152 Vistara UK-
822 Chennai Morning one Evenin
300153 rows Ã— 12 columns
1
2
df = pd.read_csv('Clean_Dataset.csv')
df
airline source_city departure_time stops arrival_time destination_cit
0 SpiceJet Delhi Evening zero Night Mumba
1 SpiceJet Delhi Early_Morning zero Morning Mumba
2 AirAsia Delhi Early_Morning zero Early_Morning Mumba
3 Vistara Delhi Morning zero Afternoon Mumba
4 Vistara Delhi Morning zero Morning Mumba
... ... ... ... ... ... .
300148 Vistara Chennai Morning one Evening Hyderaba
300149 Vistara Chennai Afternoon one Night Hyderaba
300150 Vistara Chennai Early_Morning one Night Hyderaba
300151 Vistara Chennai Early_Morning one Evening Hyderaba
300152 Vistara Chennai Morning one Evening Hyderaba
300153 rows Ã— 10 columns
1
2
df2 = df.drop(columns=['Unnamed: 0','flight'])
df2
Exploratory Data Analysis
<matplotlib.axes._subplots.AxesSubplot at 0x7f534ae111f0>
1 sns.barplot(data=df, x="airline",y="price", hue="class")
1 sns.barplot(data=df, x="airline",y="duration", hue="class")
12/28/22, 2:20 PM Flight Price Prediction.ipynb - Colaboratory
https://colab.research.google.com/drive/1So4Cg5JF6SMfEj-k8bmOkkWxozuf7eXk#scrollTo=0NgCPHWvmApW&printMode=true 2/5
<matplotlib.axes._subplots.AxesSubplot at 0x7f534ac75670>
<matplotlib.axes._subplots.AxesSubplot at 0x7f534ac11730>
1 sns.barplot(data=df, x="stops", y="price")
<matplotlib.axes._subplots.AxesSubplot at 0x7f534abe03d0>
1 sns.countplot(data=df, x="stops", hue="airline")
<matplotlib.axes._subplots.AxesSubplot at 0x7f534ace4a90>
1 sns.barplot(data=df, x="destination_city", y="price")
Data Preprocessing
1 df['source_city'].unique()
array(['Delhi', 'Mumbai', 'Bangalore', 'Kolkata', 'Hyderabad', 'Chennai'],
dtype=object)
1 df['departure_time'].unique()
array(['Evening', 'Early_Morning', 'Morning', 'Afternoon', 'Night',
'Late_Night'], dtype=object)
1 df['arrival_time'].unique()
array(['Night', 'Morning', 'Early_Morning', 'Afternoon', 'Evening',
'Late_Night'], dtype=object)
1 df['destination_city'].unique()
array(['Mumbai', 'Bangalore', 'Kolkata', 'Hyderabad', 'Chennai', 'Delhi'],
dtype=object)
12/28/22, 2:20 PM Flight Price Prediction.ipynb - Colaboratory
https://colab.research.google.com/drive/1So4Cg5JF6SMfEj-k8bmOkkWxozuf7eXk#scrollTo=0NgCPHWvmApW&printMode=true 3/5
airline source_city departure_time stops arrival_time destination_city cl
0 0 0 0 0 4 1
1 0 0 1 0 2 1
2 1 0 1 0 1 1
3 2 0 2 0 3 1
4 2 0 2 0 2 1
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
#Change value in airline column
df2['airline'] = df2['airline'].replace(['SpiceJet'],'0')
df2['airline'] = df2['airline'].replace(['AirAsia'],'1')
df2['airline'] = df2['airline'].replace(['Vistara'],'2')
df2['airline'] = df2['airline'].replace(['GO_FIRST'],'3')
df2['airline'] = df2['airline'].replace(['Indigo'],'4')
df2['airline'] = df2['airline'].replace(['Air_India'],'5')
#Change value in source_city column
df2['source_city'] = df2['source_city'].replace(['Delhi'],'0')
df2['source_city'] = df2['source_city'].replace(['Mumbai'],'1')
df2['source_city'] = df2['source_city'].replace(['Bangalore'],'2')
df2['source_city'] = df2['source_city'].replace(['Kolkata'],'3')
df2['source_city'] = df2['source_city'].replace(['Hyderabad'],'4')
df2['source_city'] = df2['source_city'].replace(['Chennai'],'5')
#Change value in departure_time column
df2['departure_time'] = df2['departure_time'].replace(['Evening'],'0')
df2['departure_time'] = df2['departure_time'].replace(['Early_Morning'],'1')
df2['departure_time'] = df2['departure_time'].replace(['Morning'],'2')
df2['departure_time'] = df2['departure_time'].replace(['Afternoon'],'3')
df2['departure_time'] = df2['departure_time'].replace(['Night'],'4')
df2['departure_time'] = df2['departure_time'].replace(['Late_Night'],'5')
#Change value in stops column
df2['stops'] = df2['stops'].replace(['zero'],'0')
df2['stops'] = df2['stops'].replace(['one'],'1')
df2['stops'] = df2['stops'].replace(['two_or_more'],'2')
#Change value in arrival_time column
df2['arrival_time'] = df2['arrival_time'].replace(['Evening'],'0')
df2['arrival_time'] = df2['arrival_time'].replace(['Early_Morning'],'1')
df2['arrival_time'] = df2['arrival_time'].replace(['Morning'],'2')
df2['arrival_time'] = df2['arrival_time'].replace(['Afternoon'],'3')
df2['arrival_time'] = df2['arrival_time'].replace(['Night'],'4')
df2['arrival_time'] = df2['arrival_time'].replace(['Late_Night'],'5')
#Change value in destination_city column
df2['destination_city'] = df2['destination_city'].replace(['Delhi'],'0')
df2['destination_city'] = df2['destination_city'].replace(['Mumbai'],'1')
df2['destination_city'] = df2['destination_city'].replace(['Bangalore'],'2')
df2['destination_city'] = df2['destination_city'].replace(['Kolkata'],'3')
df2['destination_city'] = df2['destination_city'].replace(['Hyderabad'],'4')
df2['destination_city'] = df2['destination_city'].replace(['Chennai'],'5')
#Change value in class column
df2['class'] = df2['class'].replace(['Economy'],'0')
df2['class'] = df2['class'].replace(['Business'],'1')
df2.head()
1 df2.dtypes
airline object
source_city object
departure_time object
stops object
arrival_time object
destination_city object
class object
duration float64
days_left int64
price int64
dtype: object
Change object datatypes into integer
1
2
3
4
5
6
7
8
df2['airline'] = pd.to_numeric(df2['airline'])
df2['source_city'] = pd.to_numeric(df2['source_city'])
df2['departure_time'] = pd.to_numeric(df2['departure_time'])
df2['stops'] = pd.to_numeric(df2['stops'])
df2['arrival_time'] = pd.to_numeric(df2['arrival_time'])
df2['destination_city'] = pd.to_numeric(df2['destination_city'])
df2['class'] = pd.to_numeric(df2['class'])
df2.dtypes
airline int64
source_city int64
departure_time int64
stops int64
arrival_time int64
destination_city int64
class int64
duration float64
days_left int64
price int64
dtype: object
Data Correlation Heatmap
1 sns.heatmap(df2.corr(), fmt='.2g')
12/28/22, 2:20 PM Flight Price Prediction.ipynb - Colaboratory
https://colab.research.google.com/drive/1So4Cg5JF6SMfEj-k8bmOkkWxozuf7eXk#scrollTo=0NgCPHWvmApW&printMode=true 4/5
<matplotlib.axes._subplots.AxesSubplot at 0x7f534aad8520>
Machine Learning Model Building
1
2
X = df2.drop('price', axis=1)
y = df2['price']
1
2
3
4
#test size 20% and train size 80%
from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict
from sklearn.metrics import accuracy_score
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2,random_state=0)
Decision Tree Regressor
1
2
3
from sklearn.tree import DecisionTreeRegressor
dtree = DecisionTreeRegressor(random_state=0)
dtree.fit(X_train, y_train)
DecisionTreeRegressor(random_state=0)
1
2
3
4
5
6
7
8
9
10
11
12
from sklearn import metrics
import math
y_pred = dtree.predict(X_test)
mae = metrics.mean_absolute_error(y_test, y_pred)
mse = metrics.mean_squared_error(y_test, y_pred)
r2 = metrics.r2_score(y_test, y_pred)
rmse = math.sqrt(mse)
print('MAE is {}'.format(mae))
print('MSE is {}'.format(mse))
print('R2 score is {}'.format(r2))
print('RMSE score is {}'.format(rmse))
MAE is 1148.8754338036458
MSE is 11793103.737535143
R2 score is 0.976935892693374
RMSE score is 3434.1088709496594
Random Forest Regressor
1
2
3
from sklearn.ensemble import RandomForestRegressor
rf = RandomForestRegressor(random_state=0)
rf.fit(X_train, y_train)
RandomForestRegressor(random_state=0)
1
2
3
4
5
6
7
8
9
10
11
12
from sklearn import metrics
import math
y_pred = rf.predict(X_test)
mae = metrics.mean_absolute_error(y_test, y_pred)
mse = metrics.mean_squared_error(y_test, y_pred)
r2 = metrics.r2_score(y_test, y_pred)
rmse = math.sqrt(mse)
print('MAE is {}'.format(mae))
print('MSE is {}'.format(mse))
print('R2 score is {}'.format(r2))
print('RMSE score is {}'.format(rmse))
MAE is 1065.2288574434292
MSE is 7329580.679628791
R2 score is 0.9856653312758136
RMSE score is 2707.319833272159
Adaboost Regressor
1
2
3
from sklearn.ensemble import AdaBoostRegressor
ada = AdaBoostRegressor(random_state=0)
ada.fit(X_train, y_train)
12/28/22, 2:20 PM Flight Price Prediction.ipynb - Colaboratory
https://colab.research.google.com/drive/1So4Cg5JF6SMfEj-k8bmOkkWxozuf7eXk#scrollTo=0NgCPHWvmApW&printMode=true 5/5
î—Š 0s completed at 2:18 PM
AdaBoostRegressor(random_state=0)
1
2
3
4
5
6
7
8
9
10
11
12
from sklearn import metrics
import math
y_pred = ada.predict(X_test)
mae = metrics.mean_absolute_error(y_test, y_pred)
mse = metrics.mean_squared_error(y_test, y_pred)
r2 = metrics.r2_score(y_test, y_pred)
rmse = math.sqrt(mse)
print('MAE is {}'.format(mae))
print('MSE is {}'.format(mse))
print('R2 score is {}'.format(r2))
print('RMSE score is {}'.format(rmse))
MAE is 3636.786046750951
MSE is 33527783.060335092
R2 score is 0.9344287641771843
RMSE score is 5790.318044834419
